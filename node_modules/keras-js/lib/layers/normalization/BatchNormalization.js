'use strict';

Object.defineProperty(exports, "__esModule", {
  value: true
});

var _createClass = function () { function defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if ("value" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } } return function (Constructor, protoProps, staticProps) { if (protoProps) defineProperties(Constructor.prototype, protoProps); if (staticProps) defineProperties(Constructor, staticProps); return Constructor; }; }();

var _get = function get(object, property, receiver) { if (object === null) object = Function.prototype; var desc = Object.getOwnPropertyDescriptor(object, property); if (desc === undefined) { var parent = Object.getPrototypeOf(object); if (parent === null) { return undefined; } else { return get(parent, property, receiver); } } else if ("value" in desc) { return desc.value; } else { var getter = desc.get; if (getter === undefined) { return undefined; } return getter.call(receiver); } };

var _Layer2 = require('../../Layer');

var _Layer3 = _interopRequireDefault(_Layer2);

var _Tensor = require('../../Tensor');

var _Tensor2 = _interopRequireDefault(_Tensor);

var _ndarrayOps = require('ndarray-ops');

var _ndarrayOps2 = _interopRequireDefault(_ndarrayOps);

var _ndarrayUnpack = require('ndarray-unpack');

var _ndarrayUnpack2 = _interopRequireDefault(_ndarrayUnpack);

var _flattenDeep = require('lodash/flattenDeep');

var _flattenDeep2 = _interopRequireDefault(_flattenDeep);

var _checkPipelineSupport = require('../../utils/checkPipelineSupport');

var _checkPipelineSupport2 = _interopRequireDefault(_checkPipelineSupport);

var _WebGLBatchNorm = require('../../ext/normalization/WebGLBatchNorm');

var _WebGLBatchNorm2 = _interopRequireDefault(_WebGLBatchNorm);

function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }

function _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError("Cannot call a class as a function"); } }

function _possibleConstructorReturn(self, call) { if (!self) { throw new ReferenceError("this hasn't been initialised - super() hasn't been called"); } return call && (typeof call === "object" || typeof call === "function") ? call : self; }

function _inherits(subClass, superClass) { if (typeof superClass !== "function" && superClass !== null) { throw new TypeError("Super expression must either be null or a function, not " + typeof superClass); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, enumerable: false, writable: true, configurable: true } }); if (superClass) Object.setPrototypeOf ? Object.setPrototypeOf(subClass, superClass) : subClass.__proto__ = superClass; }

/**
 * BatchNormalization layer class
 */
var BatchNormalization = function (_Layer) {
  _inherits(BatchNormalization, _Layer);

  /**
   * Creates an BatchNormalization layer
   */
  function BatchNormalization() {
    var attrs = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};

    _classCallCheck(this, BatchNormalization);

    var _this = _possibleConstructorReturn(this, (BatchNormalization.__proto__ || Object.getPrototypeOf(BatchNormalization)).call(this, attrs));

    _this.layerClass = 'BatchNormalization';

    var _attrs$epsilon = attrs.epsilon,
        epsilon = _attrs$epsilon === undefined ? 0.001 : _attrs$epsilon,
        _attrs$mode = attrs.mode,
        mode = _attrs$mode === undefined ? 0 : _attrs$mode,
        _attrs$axis = attrs.axis,
        axis = _attrs$axis === undefined ? -1 : _attrs$axis;


    _this.epsilon = epsilon;
    _this.mode = mode;

    // no batch axis, so axis is less 1 compared to representation in keras
    // will be set in call(), as input tensor shape is needed to calculate axis
    // if axis < 0
    _this.axis = axis;
    _this.axisNormalized = false;

    // Layer weights specification
    // running mean and std are non_trainable_weights in mode 0
    _this.params = _this.mode === 0 ? ['gamma', 'beta', 'running_mean', 'running_std'] : ['gamma', 'beta'];

    // Enable layer gpu +/- pipeline mode if supported
    if (_this.gpu && weblas) {
      _this._useWeblas = true;
      if (_this.pipeline) {
        var isPipelineModeSupported = (0, _checkPipelineSupport2.default)(_this.layerClass, attrs);
        if (isPipelineModeSupported) {
          _this._pipelineEnabled = true;
          _this.webglBatchNorm = new _WebGLBatchNorm2.default();
        } else {
          _this._pipelineEnabled = false;
        }
      }
    }
    return _this;
  }

  /**
   * Method for setting layer weights. Extends `super` method.
   * @param {Tensor[]} weightsArr - array of weights which are instances of Tensor
   */


  _createClass(BatchNormalization, [{
    key: 'setWeights',
    value: function setWeights(weightsArr) {
      var _this2 = this;

      _get(BatchNormalization.prototype.__proto__ || Object.getPrototypeOf(BatchNormalization.prototype), 'setWeights', this).call(this, weightsArr);

      if (this._useWeblas) {
        this.params.forEach(function (param) {
          _this2.weights[param].createWeblasTensor();
        });
      }
    }

    /**
     * Runs layer computational logic in pipeline mode
     * Only works with a previous convolutional layer with its output containing
     * a weblas pipeline tensor which is a 2-D tiled representation (tile data, channels).
     * The output after normalization is still a 2-D tiled representation (typically as input
     * to convolution or merge layers running in pipeline mode).
     * @param {Tensor} x
     * @returns {Tensor} x
     */

  }, {
    key: '_callPipelineMode',
    value: function _callPipelineMode(x) {
      if (!x._fromPipeline) {
        return this._callRegularMode(x);
      }

      x.weblasTensor = this.webglBatchNorm.call(x.weblasTensor, this.epsilon, this.weights.gamma.weblasTensor, this.weights.beta.weblasTensor, this.weights.running_mean.weblasTensor, this.weights.running_std.weblasTensor);

      return x;
    }

    /**
     * Runs layer computational logic in regular mode
     * @param {Tensor} x
     * @returns {Tensor} x
     */

  }, {
    key: '_callRegularMode',
    value: function _callRegularMode(x) {
      var _this3 = this;

      if (!this.axisNormalized) {
        this.axis = this.axis < 0 ? x.tensor.shape.length + this.axis : this.axis - 1;
        this.axisNormalized = true;
      }

      var broadcast = [];
      for (var d = 0; d < x.tensor.shape.length; d++) {
        if (d === this.axis) broadcast.push(1);else broadcast.push(null);
      }

      // broadcast weights
      var _gamma = new _Tensor2.default([], x.tensor.shape);
      var _beta = new _Tensor2.default([], x.tensor.shape);
      for (var i = 0; i < x.tensor.shape[this.axis]; i++) {
        var _gamma$tensor, _beta$tensor;

        broadcast[this.axis] = i;
        _ndarrayOps2.default.assigns((_gamma$tensor = _gamma.tensor).pick.apply(_gamma$tensor, broadcast), this.weights.gamma.tensor.get(i));
        _ndarrayOps2.default.assigns((_beta$tensor = _beta.tensor).pick.apply(_beta$tensor, broadcast), this.weights.beta.tensor.get(i));
      }

      var _mean = new _Tensor2.default([], x.tensor.shape);
      var _std = new _Tensor2.default([], x.tensor.shape);

      if (this.mode === 0) {
        // feature-wise normalization
        for (var _i = 0; _i < x.tensor.shape[this.axis]; _i++) {
          var _mean$tensor, _std$tensor;

          broadcast[this.axis] = _i;
          _ndarrayOps2.default.assigns((_mean$tensor = _mean.tensor).pick.apply(_mean$tensor, broadcast), this.weights.running_mean.tensor.get(_i));
          _ndarrayOps2.default.assigns((_std$tensor = _std.tensor).pick.apply(_std$tensor, broadcast), this.weights.running_std.tensor.get(_i) + this.epsilon);
        }
        _ndarrayOps2.default.sqrteq(_std.tensor);
      } else if (this.mode === 1) {
        // sample-wise normalization
        var reducedShape = x.tensor.shape.slice();
        reducedShape.splice(this.axis, 1);

        // mean
        var sampleMean = new _Tensor2.default([], reducedShape);
        for (var _i2 = 0; _i2 < x.tensor.shape[this.axis]; _i2++) {
          var _x$tensor;

          broadcast[this.axis] = _i2;
          _ndarrayOps2.default.addeq(sampleMean.tensor, (_x$tensor = x.tensor).pick.apply(_x$tensor, broadcast));
        }
        _ndarrayOps2.default.divseq(sampleMean.tensor, x.tensor.shape[this.axis]);

        // stddev
        var sampleStd = new _Tensor2.default([], reducedShape);
        var stdTemp = new _Tensor2.default([], reducedShape);
        for (var _i3 = 0; _i3 < x.tensor.shape[this.axis]; _i3++) {
          var _x$tensor2;

          broadcast[this.axis] = _i3;
          _ndarrayOps2.default.sub(stdTemp.tensor, (_x$tensor2 = x.tensor).pick.apply(_x$tensor2, broadcast), sampleMean.tensor);
          _ndarrayOps2.default.powseq(stdTemp.tensor, 2);
          _ndarrayOps2.default.addeq(sampleStd.tensor, stdTemp.tensor);
        }
        _ndarrayOps2.default.divseq(sampleStd.tensor, x.tensor.shape[this.axis]);
        _ndarrayOps2.default.addseq(sampleStd.tensor, this.epsilon);
        _ndarrayOps2.default.sqrteq(sampleStd.tensor);
        _ndarrayOps2.default.addseq(sampleStd.tensor, this.epsilon);

        // broadcast
        for (var _i4 = 0; _i4 < x.tensor.shape[this.axis]; _i4++) {
          var _mean$tensor2, _std$tensor2;

          broadcast[this.axis] = _i4;
          _ndarrayOps2.default.assign((_mean$tensor2 = _mean.tensor).pick.apply(_mean$tensor2, broadcast), sampleMean.tensor);
          _ndarrayOps2.default.assign((_std$tensor2 = _std.tensor).pick.apply(_std$tensor2, broadcast), sampleStd.tensor);
        }
      } else if (this.mode === 2) {
        var _loop = function _loop(_i5) {
          var _x$tensor3, _mean$tensor3, _std$tensor3;

          broadcast[_this3.axis] = _i5;
          var reduction = (0, _flattenDeep2.default)((0, _ndarrayUnpack2.default)((_x$tensor3 = x.tensor).pick.apply(_x$tensor3, broadcast)));
          var axisMean = reduction.reduce(function (a, b) {
            return a + b;
          }, 0) / reduction.length;
          var axisStd = reduction.map(function (x) {
            return (x - axisMean) * (x - axisMean);
          }).reduce(function (a, b) {
            return a + b;
          }, 0) / reduction.length;
          _ndarrayOps2.default.assigns((_mean$tensor3 = _mean.tensor).pick.apply(_mean$tensor3, broadcast), axisMean);
          _ndarrayOps2.default.assigns((_std$tensor3 = _std.tensor).pick.apply(_std$tensor3, broadcast), axisStd + _this3.epsilon);
        };

        // feature-wise normalization, using per-batch statistics
        // here, batch size always = 1
        for (var _i5 = 0; _i5 < x.tensor.shape[this.axis]; _i5++) {
          _loop(_i5);
        }
        _ndarrayOps2.default.sqrteq(_std.tensor);
      } else {
        throw new Error(`[normalization.BatchNormalization] Invalid mode ${this.mode}.`);
      }

      _ndarrayOps2.default.subeq(x.tensor, _mean.tensor);
      _ndarrayOps2.default.diveq(x.tensor, _std.tensor);
      _ndarrayOps2.default.muleq(x.tensor, _gamma.tensor);
      _ndarrayOps2.default.addeq(x.tensor, _beta.tensor);

      return x;
    }

    /**
     * Method for layer computational logic
     * @param {Tensor} x
     * @returns {Tensor} x
     */

  }, {
    key: 'call',
    value: function call(x) {
      if (this._pipelineEnabled) {
        return this._callPipelineMode(x);
      } else {
        return this._callRegularMode(x);
      }
    }
  }]);

  return BatchNormalization;
}(_Layer3.default);

exports.default = BatchNormalization;